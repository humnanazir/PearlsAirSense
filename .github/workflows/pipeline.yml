name: AQI Data + Feature + Training Pipeline

on:
  schedule:
    - cron: "0 * * * *"   # Run every hour
  workflow_dispatch:       # Allow manual trigger

jobs:
  aqi-full-pipeline:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: 123
          POSTGRES_DB: aqi_feature_store
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install feast psycopg2-binary pandas numpy scikit-learn

      - name: Step 1 - Fetch New AQI & Weather Data
        run: python scripts/get_new_aqi_weather.py

      - name: Step 2 - Clean & Perform Feature Engineering
        run: python scripts/data_clean_feature.py

      - name: Step 3 - Save Data to PostgreSQL
        run: python scripts/data_to_postgres.py

      - name: Step 4 - Register Features in Feast
        run: python aqi_feature_store/feature_repo/aqi_features.py

      - name: Step 5 - Train ML Model
        run: python scripts/train.py

      - name: Upload trained model
        uses: actions/upload-artifact@v4
        with:
          name: trained-model
          path: models/
